# BCP 和 BulkCopy 超时时间说明

## 概述

在BCP和BulkCopy归档模式中,**超时时间**是一个关键的配置参数,用于控制单次数据传输操作的最大允许时间。

## 参数位置

- **BCP模式**: `BcpTimeoutSeconds`,默认值 3600 秒 (1小时)
- **BulkCopy模式**: `BulkCopyTimeoutSeconds`,默认值 3600 秒 (1小时)

这两个参数在向导的**Step 2: 填写参数**步骤中配置,并在**Step 3: 预检结果**中显示确认。

## 超时时间的作用范围

### BCP 模式

超时时间控制 `bcp.exe` 命令执行的最大时长:

```bash
bcp "SELECT * FROM [schema].[table]" queryout "temp.dat" -S server -d database -T -n -t 3600
                                                                                        ^^^^
                                                                                      超时参数
```

**具体行为**:
- 如果 BCP 导出/导入操作在指定时间内未完成,操作将被中止
- 超时时间从开始执行 bcp 命令计时,直到命令完成或超时
- 包括网络传输、磁盘I/O、数据转换等全部时间

### BulkCopy 模式

超时时间设置在 `SqlBulkCopy.BulkCopyTimeout` 属性上:

```csharp
using var bulkCopy = new SqlBulkCopy(targetConnection)
{
    BulkCopyTimeout = BulkCopyTimeoutSeconds, // 3600秒
    BatchSize = BulkCopyBatchSize,
    NotifyAfter = BulkCopyNotifyAfterRows
};

await bulkCopy.WriteToServerAsync(reader, cancellationToken);
```

**具体行为**:
- 如果单次 `WriteToServerAsync` 调用在指定时间内未完成,将抛出 `SqlException`
- 超时时间从开始写入数据计时,包括所有批次的写入时间总和
- 包括网络传输、事务提交、索引更新等全部时间

## 对超大数据归档的影响

### 会影响超大数据归档的场景

| 场景 | 问题描述 | 建议 |
|------|---------|------|
| 亿级数据量表 | 即使批次处理,总传输时间可能超过3600秒 | 将超时时间增加到 7200 或 10800 秒 |
| 慢速网络环境 | 跨机房/跨地域归档,网络延迟高 | 增加超时时间,或在本地机房执行 |
| 复杂数据类型 | BLOB/CLOB 大字段,序列化时间长 | 增加超时时间,考虑排除大字段 |
| 高并发环境 | 数据库资源竞争,锁等待时间长 | 在业务低峰期执行,增加超时时间 |
| 目标表有大量索引 | BulkCopy写入时需要维护索引 | 临时禁用索引,归档后重建 |

### 不会影响的场景(批次处理)

**重要**: 超时时间是针对**单次完整操作**,而不是单个批次:

- ✅ **BCP模式**: 导出整个表到文件的全过程算一次操作
- ✅ **BulkCopy模式**: 整个 `WriteToServerAsync` 调用算一次操作,即使内部分多个批次

**示例**: 1亿行数据,批次大小10000行
- 实际会分为 10000 个批次执行
- 但超时时间是整个1亿行传输的总时长限制,不是单个批次的限制

## 如何判断是否需要调整超时时间

### 计算公式(粗略估算)

```
预估传输时间 = (行数 × 平均行大小) / 网络带宽 + (行数 / 批次大小) × 批次提交开销

建议超时时间 = 预估传输时间 × 1.5 ~ 2.0 (留出安全余量)
```

### 实际案例

| 数据量 | 平均行大小 | 网络环境 | 建议超时时间 |
|--------|-----------|----------|-------------|
| 100万行 | 500字节 | 千兆局域网 | 600秒 (10分钟) |
| 1000万行 | 1KB | 千兆局域网 | 3600秒 (1小时,默认值) |
| 1亿行 | 1KB | 千兆局域网 | 10800秒 (3小时) |
| 1000万行 | 5KB | 百兆广域网 | 14400秒 (4小时) |
| 1亿行 | 500字节 | 跨地域 | 21600秒 (6小时) |

## 超时后的行为

### BCP 模式

如果超时,将会:
1. `bcp.exe` 进程被终止
2. 临时文件可能不完整
3. 后台任务状态更新为**失败**
4. 日志记录超时错误: `System.TimeoutException: The operation has timed out`

**数据一致性**:
- ❌ 已导出的临时文件无效,需要重新执行
- ❌ 如果在导入阶段超时,目标表可能有部分数据(取决于是否开启事务)

### BulkCopy 模式

如果超时,将会:
1. `SqlBulkCopy.WriteToServerAsync` 抛出异常
2. 当前事务回滚(如果使用事务)
3. 后台任务状态更新为**失败**
4. 日志记录: `SqlException: Timeout expired. The timeout period elapsed...`

**数据一致性**:
- ✅ 如果使用事务,数据完全回滚,目标表保持原状
- ⚠️ 如果未使用事务,可能有部分数据已写入

## 建议的最佳实践

### 1. 预估数据量

在执行归档前,先查询表的数据量和大小:

```sql
-- 查询表行数
SELECT COUNT(*) FROM [schema].[table];

-- 查询表占用空间
EXEC sp_spaceused '[schema].[table]';
```

### 2. 分段归档

如果数据量特别大(如超过1亿行),建议:
- 使用**分区切换模式**(最快,秒级完成)
- 或者将数据按时间范围分段归档,每次归档一个时间段

### 3. 监控执行进度

BulkCopy模式支持进度通知(`NotifyAfterRows`参数):
- 默认每50000行报告一次进度
- 通过日志可以看到实际传输速度,用于调整超时时间

### 4. 测试验证

在生产环境执行前:
1. 用少量数据(如100万行)测试一次
2. 记录实际耗时
3. 根据实际耗时推算完整归档所需时间
4. 设置超时时间为推算值的 1.5~2 倍

### 5. 错误重试

如果因超时失败:
1. 检查数据库和网络状态
2. 增加超时时间(建议翻倍)
3. 考虑在业务低峰期重新执行
4. 如果仍然失败,考虑改用**分区切换模式**

## 相关配置参数

| 参数 | 默认值 | 说明 | 影响超时的因素 |
|------|--------|------|---------------|
| BcpBatchSize | 10000 | BCP批次大小 | 批次越大,单次I/O越大,可能增加超时风险 |
| BcpUseNativeFormat | true | 使用原生格式 | 原生格式传输更快,减少超时风险 |
| BcpMaxErrors | 10 | 最大错误数 | 错误过多会导致重试,增加总耗时 |
| BulkCopyBatchSize | 10000 | BulkCopy批次大小 | 同BCP |
| BulkCopyEnableStreaming | true | 启用流式读取 | 流式读取减少内存占用,但可能增加网络往返次数 |
| BulkCopyNotifyAfterRows | 50000 | 进度通知间隔 | 仅影响日志频率,不影响性能 |

## 总结

### 关键要点

1. **超时时间是总耗时限制**,不是单批次限制
2. **默认3600秒(1小时)适合中等规模数据**(千万级)
3. **超大数据(亿级)需要增加超时时间**到 3~6 小时
4. **优先使用分区切换模式**,BCP/BulkCopy是备选方案
5. **生产环境前务必测试**,根据实际情况调整

### 修改建议

如果您的表数据量超过 **5000万行** 或 **单表超过50GB**,建议:
- 将超时时间增加到 **7200秒(2小时)** 或更高
- 或考虑使用**分区切换模式**,可在几秒内完成归档
- 或按时间范围分段归档,每次处理较小的数据集
